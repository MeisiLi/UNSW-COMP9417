**supervised vs un supervised**

**Linear Regression**

Loss Func 

Sum of Square Error

Residual of Sum of Square Error(RSS)

To minimize the square error

Algos ==> gradient descent, by changing the theta to minimize the loss fuc

update of the squared dist ==> LMS ==> Windrow-Hoff